{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some experiments like binary classification, three class classification and some interesting findings observed while building those models. The NDCG scorer used in the notebook is a script that was available in Kaggle. NDCG scorer: https://www.kaggle.com/davidgasquez/airbnb-recruiting-new-user-bookings/ndcg-scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : date_first_booking based prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen during the exploratory analysis, 58% of the data has the country destination as 'NDF' (No Destination Found). Also, it was found that there is a 1-to-1 correlation betweeen NaN 'date_first_booking' and 'NDF'. That is, the date_first_booking is NaN for all the instances whose country destination is 'NDF'. \n",
    "\n",
    "So in this part, I am using this information to have a model which predicts the country_destination as NDF with the date_first_booking is NaN. Therefore I drop all the rows with country_destination as NDF from the training data and using RandomForest Classifier to train the remaining data. Once we get the prediction for the remaining countries, I append the prediction list with NDF for all the records in the test data that has the date_first_booking as NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split train-test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data = pd.read_csv('preprocessed_airbnb_train.csv')\n",
    "labels = data.loc[:,'country_destination']\n",
    "data = data.drop(['country_destination'], axis=1)\n",
    "\n",
    "[tr_data, te_data, \n",
    " tr_labels, te_labels] = cross_validation.train_test_split(data, labels, random_state=20160202, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "#def ndcg_score(ground_truth, predictions, k=5):\n",
    "def ndcg_score(te_labels, predict, k):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predict) + 1))\n",
    "    T = lb.transform(te_labels)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predict):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)  \n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all NDF rows from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = tr_data.copy()\n",
    "train['country_destination'] = tr_labels\n",
    "\n",
    "# NDF is encoded as 0\n",
    "train_ndf_dropped = train[ train.country_destination != 0 ]\n",
    "\n",
    "tr_labels = train_ndf_dropped.loc[:,'country_destination']\n",
    "tr_data = train_ndf_dropped.drop(['country_destination'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=600,criterion='gini', min_samples_leaf=50)\n",
    "rf = rf.fit(tr_data, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_predict = rf.predict_proba( te_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the prediction, to mark 1.0 NDF probability for NaN date_first_booking and 0 for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.insert(rf_predict, 0, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te = te_data.copy()\n",
    "for i in range(12):\n",
    "    te['pr%d'%i] = x[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te.loc[ te.dfb_year == 0, 'pr0'] = 1.0\n",
    "for i in range(1,12):\n",
    "    te.loc[ te.dfb_year == 0, 'pr%d'%i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_col = [col for col in list(te) if col.startswith('pr')]\n",
    "rf_predict_fixed = te[filter_col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NDCG score for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927350768403\n"
     ]
    }
   ],
   "source": [
    "score = ndcg_score(te_labels.as_matrix(), rf_predict_fixed, k=5)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that we can leverage the 1-to-1 coorelation information between certain values in the attribute and labels to improve the score drastically, though it might be biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 :  NDF prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to get a more realistic model, in this section I will try to build models on the preprocessed data without the date_first_booking information. \n",
    "\n",
    "The model here is a two level classifier. The first level is a Binary classifier which will predict whether the country is NDF or not. In the second level, a multi-class classifier will classify the data among the valid countries. The first level classifier is chosen by comparing the performance of Linear Regression and a boosted DecisionTree. The second level classifier is RandomForest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update labels to classify as either NDF or non-NDF destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop date_first_booking information and perform StandardScaler on the remanining data\n",
    "ndf_data = data.drop(['dfb_year', 'dfb_month', 'dfb_day'], axis=1)\n",
    "ndf_data = pd.DataFrame(preprocessing.StandardScaler().fit_transform(ndf_data))\n",
    "\n",
    "[tr_data, te_data, \n",
    " tr_labels, te_labels] = cross_validation.train_test_split(ndf_data, labels, random_state=20160202, test_size=0.33)\n",
    "\n",
    "tr_labels_adjusted = tr_labels.copy()\n",
    "# Mark all valid countries as 1 and NDF as 0\n",
    "tr_labels_adjusted.loc[ tr_labels_adjusted[::] > 0 ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.595408793424\n"
     ]
    }
   ],
   "source": [
    "lr_predict_corrected_2 = [ 1 if v > 0.5 else 0 for v in lr_predict.flatten()]\n",
    "te_labels_adjusted = te_labels.copy()\n",
    "te_labels_adjusted.loc[ te_labels_adjusted[::] > 0 ] = 1\n",
    "correct = 0\n",
    "for l, t in zip(te_labels_adjusted, lr_predict_corrected_2):\n",
    "    if l==t:\n",
    "        correct += 1\n",
    "\n",
    "print float(correct)/float(len(te_labels_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Linear Regression doesn't classify the NDF labels very well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 : Binary classification for US/Non-US prediction without NDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I am trying to come up with a model to predict the valid countries. Hence dropping all the rows with NDF as country_destination. In the data exploration part, it can be seen that almost 30% data has the country_destination as U.S.A. So in this model, I am using Linear Regression, Boosted Decision Tree and LinearSVC to classify between US and non-US and select the the best method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_airbnb_train.csv')\n",
    "data = data[ data.country_destination != 0 ]\n",
    "labels = data.loc[:,'country_destination']\n",
    "data = data.drop(['country_destination'], axis=1)\n",
    "\n",
    "data = pd.DataFrame(preprocessing.StandardScaler().fit_transform(data))\n",
    "\n",
    "[tr_data, te_data, \n",
    " tr_labels, te_labels] = cross_validation.train_test_split(data, labels, random_state=20160202, test_size=0.33)\n",
    "\n",
    "tr_labels_adjusted = tr_labels.copy()\n",
    "# Mark all non-US countries as 0 and US is 1\n",
    "tr_labels_adjusted.loc[ tr_labels_adjusted[::] > 1 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classifier using AdaBoost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         n_estimators=200)\n",
    "dt.fit(tr_data, tr_labels_adjusted.values.ravel())\n",
    "dt_predict = dt.predict(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7030334015\n"
     ]
    }
   ],
   "source": [
    "dt_predict_corrected_2 = [ 1 if v > 0.5 else 0 for v in dt_predict.flatten()]\n",
    "te_labels_adjusted = te_labels.copy()\n",
    "te_labels_adjusted.loc[ te_labels_adjusted[::] > 1 ] = 0\n",
    "correct = 0\n",
    "for l, t in zip(te_labels_adjusted, dt_predict_corrected_2):\n",
    "    if l==t:\n",
    "        correct += 1\n",
    "\n",
    "print float(correct)/float(len(te_labels_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that all the three models gave an accuracy of 70%. This is because, after removing the NDF values, 70% of the data belong to US. A blind prediction of US to all the instances would give the same accuracy score. The data is highly skewed and none of the models gave an accuracy better than the baseline of 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to change the proportion of US and Non-US countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     62376\n",
       "2     10094\n",
       "3      5023\n",
       "4      2835\n",
       "5      2324\n",
       "6      2249\n",
       "7      1428\n",
       "8      1061\n",
       "9       762\n",
       "10      539\n",
       "11      217\n",
       "Name: country_destination, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above distribution of the labels that there is a disproportionate number of countries labelled as US. So I tried to balance the dataset by sampling only 25,000 records which had the labels as US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_airbnb_train.csv')\n",
    "data = data[ data.country_destination != 0 ]\n",
    "data_us = data[ data.country_destination == 1 ]\n",
    "data_us = data_us.sample(n=25000)\n",
    "data = data[ data.country_destination != 1 ]\n",
    "data = data.append( data_us )\n",
    "\n",
    "labels = data.loc[:,'country_destination']\n",
    "data = data.drop(['country_destination'], axis=1)\n",
    "\n",
    "data = pd.DataFrame(preprocessing.StandardScaler().fit_transform(data))\n",
    "\n",
    "[tr_data, te_data, \n",
    " tr_labels, te_labels] = cross_validation.train_test_split(data, labels, random_state=20160202, test_size=0.33)\n",
    "\n",
    "tr_labels_adjusted = tr_labels.copy()\n",
    "# Mark all non-US countries as 0 and US is 1\n",
    "tr_labels_adjusted.loc[ tr_labels_adjusted[::] > 1 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(tr_data, tr_labels_adjusted.values.ravel())\n",
    "lr_predict = lr.predict(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525638010114\n"
     ]
    }
   ],
   "source": [
    "lr_predict_corrected_2 = [ 1 if v > 0.5 else 0 for v in lr_predict.flatten()]\n",
    "te_labels_adjusted = te_labels.copy()\n",
    "te_labels_adjusted.loc[ te_labels_adjusted[::] > 1 ] = 0\n",
    "correct = 0\n",
    "for l, t in zip(te_labels_adjusted, lr_predict_corrected_2):\n",
    "    if l==t:\n",
    "        correct += 1\n",
    "\n",
    "print float(correct)/float(len(te_labels_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this modelling also did not improve the baseline accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 : 3 Class Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the majority of the data is NDF or US, it would be interesting to see the performance of a model that predicts whether it is US, NDF or other. So, the labels are modified such that all the countries other than 'NDF' and 'US' is changed to 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessed_airbnb_train.csv')\n",
    "data = data.drop(['dfb_year', 'dfb_month', 'dfb_day'], axis=1)\n",
    "labels = data.loc[:,'country_destination']\n",
    "labels.loc[ labels[::] > 1 ] = 2\n",
    "data = data.drop(['country_destination'], axis=1)\n",
    "\n",
    "data = pd.DataFrame(preprocessing.StandardScaler().fit_transform(data))\n",
    "\n",
    "[tr_data, te_data, \n",
    " tr_labels, te_labels] = cross_validation.train_test_split(data, labels, random_state=20160202, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=600,criterion='gini', min_samples_leaf=50, random_state=20160202)\n",
    "rf = rf.fit(tr_data, tr_labels)\n",
    "rf_predict = rf.predict_proba( te_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845515158034\n"
     ]
    }
   ],
   "source": [
    "score = ndcg_score(te_labels.as_matrix(), rf_predict, k=3)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6252076264569344"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(te_data, te_labels_012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nDCG score is 0.845 which is pretty good for this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
